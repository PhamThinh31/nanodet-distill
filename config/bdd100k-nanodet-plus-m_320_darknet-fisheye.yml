# nanodet-plus-m_416
# COCO mAP(0.5:0.95) = 0.304
#             AP_50  = 0.459
#             AP_75  = 0.317
#           AP_small = 0.106
#               AP_m = 0.322
#               AP_l = 0.477
save_dir: workspace/bdd100k-darknet_320_fisheye-resize
model:
  weight_averager:
    name: ExpMovingAverager
    decay: 0.9998
  arch:
    name: NanoDetPlus
    detach_epoch: 10
    backbone:
      # name: ShuffleNetV2
      # model_size: 1.0x
      # out_stages: [2,3,4]
      # activation: LeakyReLU
      name: CSPDarknet
      depth: 0.33
      width: 0.25
      #in_channels: [256, 512, 1024]
      depthwise: True
      act: lrelu
    fpn:
      name: GhostPAN
      in_channels: [64, 128, 256]
      out_channels: 80
      kernel_size: 5
      num_extra_level: 1
      use_depthwise: True
      activation: LeakyReLU
    head:
      name: NanoDetPlusHead
      num_classes: 3
      input_channel: 80
      feat_channels: 80
      stacked_convs: 2
      kernel_size: 5
      # strides: [8, 16, 32, 64]
      strides: [8, 16, 32]
      activation: LeakyReLU
      reg_max: 10
      norm_cfg:
        type: BN
      loss:
        loss_qfl:
          name: QualityFocalLoss
          use_sigmoid: True
          beta: 2.0
          loss_weight: 1.0
        loss_dfl:
          name: DistributionFocalLoss
          loss_weight: 0.25
        loss_bbox:
          name: GIoULoss
          loss_weight: 2.0
    # Auxiliary head, only use in training time.
    aux_head:
      name: SimpleConvHead
      num_classes: 3
      input_channel: 160
      feat_channels: 160
      stacked_convs: 4
      # strides: [8, 16, 32, 64]
      strides: [8, 16, 32]
      activation: LeakyReLU
      reg_max: 10
data:
  train:
    name: CocoDataset
    img_path: /home/ubuntu/Workspace/datasets/bdd100k/bdd100k/images/100k/train
    ann_path: /home/ubuntu/Workspace/thinhplg-dev/domain_adaptation/od/datasets/bdd100k/v1.0/train_coco.json
    # image_size: [416,260] #[w,h]
    image_size: [1280,720] #[w,h]
    input_size: [320,256] #[w,h]
    keep_ratio: False
    # resizecrop: True
    pipeline:
      perspective: 0.0
      scale: [0.6, 1.4]
      stretch: [[0.8, 1.2], [0.8, 1.2]]
      rotation: 0
      shear: 0
      translate: 0.2
      flip: 0.5
      brightness: 0.2
      contrast: [0.6, 1.4]
      saturation: [0.5, 1.2]
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]
  val:
    name: CocoDataset
    img_path: /home/ubuntu/Workspace/datasets/bdd100k/bdd100k/images/100k/val
    ann_path: /home/ubuntu/Workspace/thinhplg-dev/domain_adaptation/od/datasets/bdd100k/v1.0/val_coco.json
    # image_size: [416,260] #[w,h]
    image_size: [1280,720] #[w,h]
    input_size: [320,256] #[w,h]
    keep_ratio: False
    # resizecrop: True
    pipeline:
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]
device:
  gpu_ids: [2,3]
  workers_per_gpu: 24
  batchsize_per_gpu: 256
schedule:
  # # resume:
  # load_model: pretrained/nanodet-plus-m_416.pth
#   optimizer:
#     name: SGD
#     lr: 0.03
#     momentum: 0.9
#     weight_decay: 0.0001
#   warmup:
#     name: linear
#     steps: 300
#     ratio: 0.1
#   total_epochs: 135
#   lr_schedule:
#     name: MultiStepLR
#     milestones: [90,110,120,130]
#     gamma: 0.1
#   val_intervals: 10
# evaluator:
#   name: CocoDetectionEvaluator
#   save_key: mAP

# log:
#   interval: 50

# class_names: ['person', 'vehicles', 'motocycle', 'dog', 'fire_hydrant']

  optimizer:
    name: AdamW
    lr: 0.0001
    weight_decay: 0.05
  warmup:
    name: linear
    steps: 500
    ratio: 0.0001
  total_epochs: 500
  lr_schedule:
    name: CosineAnnealingLR
    T_max: 200
    eta_min: 0.00005
  val_intervals: 5
grad_clip: 35
evaluator:
  name: CocoDetectionEvaluator
  save_key: mAP
log:
  interval: 50
class_names: ['cars', 'pedestrians', 'bicycle']
