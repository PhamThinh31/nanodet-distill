# nanodet-EfficientNet-Lite2_512
# COCO mAP(0.5:0.95) = 0.326
#             AP_50  = 0.501
#             AP_75  = 0.344
#           AP_small = 0.152
#               AP_m = 0.342
#               AP_l = 0.481
save_dir: workspace/efficientlite4_512
model:
  arch:
    name: OneStageDetector
    backbone:
      name: EfficientNetLite
      model_name: efficientnet_lite4
      out_stages: [2,4,6]
      activation: ReLU6
      pretrain: True
    fpn:
      name: PAN
      in_channels: [56, 160, 448]
      out_channels: 128
      start_level: 0
      num_outs: 3
    head:
      name: NanoDetPlusHead
      num_classes: 80
      input_channel: 128
      feat_channels: 128
      stacked_convs: 4
      kernel_size: 5
      strides: [8, 16, 32]
      activation: LeakyReLU
      reg_max: 10
      norm_cfg:
        type: BN
      loss:
        loss_qfl:
          name: QualityFocalLoss
          use_sigmoid: True
          beta: 2.0
          loss_weight: 1.0
        loss_dfl:
          name: DistributionFocalLoss
          loss_weight: 0.25
        loss_bbox:
          name: GIoULoss
          loss_weight: 2.0
    # Auxiliary head, only use in training time.
    aux_head:
      name: SimpleConvHead
      num_classes: 80
      input_channel: 512
      feat_channels: 512
      stacked_convs: 4
      strides: [8, 16, 32]
      activation: LeakyReLU
      reg_max: 10
data:
  train:
    name: CocoDataset
    img_path: /home/ubuntu/Workspace/datasets/coco/train2017
    ann_path: /home/ubuntu/Workspace/datasets/coco/annotations/instances_train2017.json
    input_size: [512,512] #[w,h]
    keep_ratio: True
    pipeline:
      perspective: 0.0
      scale: [0.5, 1.5]
      stretch: [[1, 1], [1, 1]]
      rotation: 0
      shear: 0
      translate: 0.2
      flip: 0.5
      brightness: 0.2
      contrast: [0.6, 1.4]
      saturation: [0.5, 1.2]
      normalize: [[127.0, 127.0, 127.0], [128.0, 128.0, 128.0]]
  val:
    name: CocoDataset
    img_path: /home/ubuntu/Workspace/datasets/coco/val2017
    ann_path: /home/ubuntu/Workspace/datasets/coco/annotations/instances_val2017.json
    input_size: [512,512] #[w,h]
    keep_ratio: True
    pipeline:
      normalize: [[127.0, 127.0, 127.0], [128.0, 128.0, 128.0]]
device:
  gpu_ids: [0,1,2,3]
  workers_per_gpu: 8
  batchsize_per_gpu: 32
schedule:
#  resume:
#  load_model: YOUR_MODEL_PATH
  optimizer:
    name: SGD
    lr: 0.03
    momentum: 0.9
    weight_decay: 0.0001
  warmup:
    name: linear
    steps: 300
    ratio: 0.1
  total_epochs: 135
  lr_schedule:
    name: MultiStepLR
    milestones: [90,110,120,130]
    gamma: 0.1
  val_intervals: 5
evaluator:
  name: CocoDetectionEvaluator
  save_key: mAP

log:
  interval: 50

class_names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
              'train', 'truck', 'boat', 'traffic_light', 'fire_hydrant',
              'stop_sign', 'parking_meter', 'bench', 'bird', 'cat', 'dog',
              'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',
              'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
              'skis', 'snowboard', 'sports_ball', 'kite', 'baseball_bat',
              'baseball_glove', 'skateboard', 'surfboard', 'tennis_racket',
              'bottle', 'wine_glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',
              'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',
              'hot_dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
              'potted_plant', 'bed', 'dining_table', 'toilet', 'tv', 'laptop',
              'mouse', 'remote', 'keyboard', 'cell_phone', 'microwave',
              'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',
              'vase', 'scissors', 'teddy_bear', 'hair_drier', 'toothbrush']
